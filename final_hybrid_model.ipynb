{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "acea1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from reviewclassifierv2 import ReviewMTLPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed9795d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         locationName            category   reviewerName      publishedAtDate  \\\n",
      "0  Gardens by the Bay  Tourist attraction  Stylusmaestro  2021-12-29 10:13:13   \n",
      "1  Gardens by the Bay  Tourist attraction      JoJo Chin  2020-03-21 09:06:31   \n",
      "2  Gardens by the Bay  Tourist attraction     Theticus _  2020-03-03 00:12:25   \n",
      "3  Gardens by the Bay  Tourist attraction        sky wda  2020-01-02 18:05:38   \n",
      "4  Gardens by the Bay  Tourist attraction    Trúc Nguyễn  2020-01-01 12:22:38   \n",
      "\n",
      "   rating                                         reviewText  \\\n",
      "0     0.5  For a weekday this is considered very crowded....   \n",
      "1     1.0  Awsome view with breeze wind. Suitable for all...   \n",
      "2     0.5  Great place to hang out and have picnic especi...   \n",
      "3     1.0  Every years great place to catch firework on S...   \n",
      "4     1.0        This is the 10 times I come here. Best view   \n",
      "\n",
      "                                           imageUrls  reviewerNumberOfReviews  \\\n",
      "0  https://lh3.googleusercontent.com/geougc-cs/AB...                     49.0   \n",
      "1                                                NaN                    201.0   \n",
      "2  https://lh3.googleusercontent.com/geougc-cs/AB...                   2181.0   \n",
      "3  https://lh3.googleusercontent.com/geougc-cs/AB...                     53.0   \n",
      "4  https://lh3.googleusercontent.com/geougc-cs/AB...                    127.0   \n",
      "\n",
      "   temporarilyClosed  qualityLevel  ...  reviewWordCount  sentimentScore  \\\n",
      "0                0.0             2  ...               32        0.001126   \n",
      "1                0.0             1  ...               11        0.999089   \n",
      "2                0.0             1  ...               12        0.999921   \n",
      "3                0.0             2  ...               28        0.999850   \n",
      "4                0.0             0  ...               10        0.997996   \n",
      "\n",
      "   sentimentRatingDiff  readabilityScore  grammarSpellingScore  hasLink  \\\n",
      "0             0.498874          0.771025              1.000000        0   \n",
      "1             0.000911          0.705070              0.909091        0   \n",
      "2             0.499921          0.818550              0.916667        0   \n",
      "3             0.000150          0.355107              0.892857        0   \n",
      "4             0.002004          1.000000              1.000000        0   \n",
      "\n",
      "   categoryRelevanceScore  imageRelevanceScore  imageQualityScore  \\\n",
      "0                0.281248             0.546696           0.856412   \n",
      "1                0.389142                  NaN                NaN   \n",
      "2                0.432605             0.546786           0.997150   \n",
      "3                0.248290             0.532493           0.963426   \n",
      "4                0.279137             0.524121           0.987667   \n",
      "\n",
      "   isAdvertisement  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Google Sheet file ID\n",
    "file_id = \"1xkgCgwFvHSIST_pRXB4zmKRGAqw3Yyti\"\n",
    "\n",
    "# Export as Excel (.xlsx)\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{file_id}/export?format=xlsx\"\n",
    "\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "# Preview\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "150ed82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rule_based(df):\n",
    "    # Ensure publishedAtDate is datetime\n",
    "    df[\"publishedAtDate\"] = pd.to_datetime(df[\"publishedAtDate\"], errors=\"coerce\")\n",
    "    \n",
    "    # Start with all NaN (means \"not yet decided\")\n",
    "    df[\"ruleQualityLabel\"] = np.nan\n",
    "    \n",
    "    # Rule 1: Link → qualityLevel = 0\n",
    "    df.loc[(df[\"hasLink\"] == 1) | (df[\"isAdvertisement\"] == 1), \"ruleQualityLabel\"] = 0\n",
    "\n",
    "    \n",
    "    # Rule 2: Spamming by same user at same location in short time\n",
    "    df = df.sort_values(by=[\"reviewerName\", \"locationName\", \"publishedAtDate\"])\n",
    "    df[\"timeDiff\"] = df.groupby([\"reviewerName\", \"locationName\"])[\"publishedAtDate\"].diff().dt.total_seconds()\n",
    "    \n",
    "    # Suspicious if multiple reviews within 10 minutes (600 sec)\n",
    "    spam_mask = df[\"timeDiff\"].notna() & (df[\"timeDiff\"] < 600)\n",
    "    df.loc[spam_mask, \"ruleQualityLabel\"] = 0\n",
    "    \n",
    "    # Rule 3: Duplicate content (exact match across reviews)\n",
    "    # Flag duplicates but do NOT delete them\n",
    "    duplicate_mask = df.duplicated(subset=[\"reviewText\"], keep=False)\n",
    "    df.loc[duplicate_mask, \"ruleQualityLabel\"] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "43b804fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df[\"qualityLevel\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "30140c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule Based:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       142\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       144\n",
      "   macro avg       0.33      0.33      0.33       144\n",
      "weighted avg       0.97      0.99      0.98       144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test = apply_rule_based(X_test)\n",
    "rule_labels = X_test[\"ruleQualityLabel\"]\n",
    "X_test = X_test[X_test[\"ruleQualityLabel\"] == 0]\n",
    "print(\"Rule Based:\")\n",
    "print(classification_report(y_true=X_test[\"qualityLevel\"], y_pred=X_test[\"ruleQualityLabel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "19b60a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_quality_labels(rule_labels, rf_probs, dual_probs):\n",
    "    \"\"\"\n",
    "    rule_labels: array of 0/1/2 from rule-based model\n",
    "    rf_probs: n_samples x 3 array from RF predict_proba\n",
    "    dual_probs: n_samples x 3 array from dual-head model predict_proba\n",
    "    \"\"\"\n",
    "    n_samples = len(rf_probs)\n",
    "    final = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    rule_labels = np.array(rule_labels)\n",
    "    rf_probs = np.array(rf_probs)\n",
    "    dual_probs = np.array(dual_probs)\n",
    "    \n",
    "    # average the probabilities for samples where rule-based != 0\n",
    "    avg_probs = (rf_probs + dual_probs) / 2\n",
    "\n",
    "    # assign final labels\n",
    "    for i in range(n_samples):\n",
    "        if rule_labels[i] == 0:\n",
    "            final[i] = 0\n",
    "        else:\n",
    "            final[i] = np.argmax(avg_probs[i])\n",
    "    \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a517f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rf\n",
    "with open('random_forest_model.pkl', 'rb') as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eb08b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "X = df[[\"readabilityScore\", \"grammarSpellingScore\", \"sentimentRatingDiff\", \"reviewWordCount\", \"imageQualityScore\"]]  \n",
    "y = df[\"qualityLevel\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "rf_probs = rf.predict_proba(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "58636cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"reviewText\"]\n",
    "y = df[\"qualityLevel\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "bundle_dir = \"artifacts/review_mtl_v1\"\n",
    "clf = ReviewMTLPredictor.from_dir(bundle_dir)\n",
    "\n",
    "pred_df = clf.predict(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7ee2287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_probs_quality = pred_df[[\"p_quality_low\", \"p_quality_medium\", \"p_quality_good\"]].values.tolist()\n",
    "dual_probs_relevance = pred_df[[\"p_relevance_irrel\", \"p_relevance_rel\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "db7cf3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  qualityLabel\n",
      "3084                      Good quality drinks and food.             0\n",
      "2984                                Seaside great view!             0\n",
      "2260                                   Great experience             0\n",
      "1979  2 hours since order and not received.\\nHorribl...             1\n",
      "1889  The interior is very beautiful. It was a bit s...             0\n"
     ]
    }
   ],
   "source": [
    "quality_labels = final_quality_labels(rule_labels, rf_probs, dual_probs_quality)\n",
    "outcome = pd.DataFrame(X_test, columns=[\"reviewText\"]) \n",
    "\n",
    "# Add the predicted labels\n",
    "outcome[\"qualityLabel\"] = quality_labels\n",
    "\n",
    "print(outcome.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d759da38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       530\n",
      "           1       0.72      0.62      0.66       334\n",
      "           2       0.66      0.76      0.71       138\n",
      "\n",
      "    accuracy                           0.77      1002\n",
      "   macro avg       0.73      0.75      0.74      1002\n",
      "weighted avg       0.77      0.77      0.76      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=quality_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "712fa4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load logistic regression\n",
    "with open('logreg_model.pkl', 'rb') as f:\n",
    "    logreg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a10f73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"categoryRelevanceScore\", \"imageRelevanceScore\"]]\n",
    "y = df[\"isRelevant\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "logreg_probs = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "505b1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_relevance_labels(dual_probs, logreg_probs):\n",
    "    dual_probs = np.array(dual_probs)  # from dual-head model\n",
    "    logreg_probs = np.array(logreg_probs)  # from logistic regression\n",
    "\n",
    "    # Average the probabilities of \"1\"\n",
    "    avg_probs_1 = (dual_probs[:, 1] + logreg_probs[:, 1]) / 2\n",
    "\n",
    "    # Convert to binary labels\n",
    "    final_labels = (avg_probs_1 >= 0.5).astype(int)\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "49544a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_labels = final_relevance_labels(dual_probs_relevance, logreg_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "df0259da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  relevanceLabel\n",
      "973   The Pyramids of Giza arent just piles of stone...               1\n",
      "1938  I have become a regular customer of this shop....               1\n",
      "3296  We came to drink beyran soup for breakfast. We...               1\n",
      "4613  The lakeside kayak rentals offered easy reserv...               1\n",
      "2743  Lovely space with view of the river and downto...               1\n"
     ]
    }
   ],
   "source": [
    "X = df[\"reviewText\"]\n",
    "y = df[\"isRelevant\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "outcome = pd.DataFrame(X_test, columns=[\"reviewText\"]) \n",
    "outcome[\"relevanceLabel\"] = relevance_labels\n",
    "print(outcome.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "34147b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.01       216\n",
      "           1       0.78      1.00      0.88       786\n",
      "\n",
      "    accuracy                           0.78      1002\n",
      "   macro avg       0.56      0.50      0.44      1002\n",
      "weighted avg       0.69      0.78      0.69      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=relevance_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfde739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
