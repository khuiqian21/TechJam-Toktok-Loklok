{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acea1231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yushi\\AppData\\Local\\Temp\\ipykernel_8856\\3933193381.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9795d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         locationName            category   reviewerName      publishedAtDate  \\\n",
      "0  Gardens by the Bay  Tourist attraction  Stylusmaestro  2021-12-29 10:13:13   \n",
      "1  Gardens by the Bay  Tourist attraction      JoJo Chin  2020-03-21 09:06:31   \n",
      "2  Gardens by the Bay  Tourist attraction     Theticus _  2020-03-03 00:12:25   \n",
      "3  Gardens by the Bay  Tourist attraction        sky wda  2020-01-02 18:05:38   \n",
      "4  Gardens by the Bay  Tourist attraction    Trúc Nguyễn  2020-01-01 12:22:38   \n",
      "\n",
      "   rating                                         reviewText  \\\n",
      "0     0.5  For a weekday this is considered very crowded....   \n",
      "1     1.0  Awsome view with breeze wind. Suitable for all...   \n",
      "2     0.5  Great place to hang out and have picnic especi...   \n",
      "3     1.0  Every years great place to catch firework on S...   \n",
      "4     1.0        This is the 10 times I come here. Best view   \n",
      "\n",
      "                                           imageUrls  reviewerNumberOfReviews  \\\n",
      "0  https://lh3.googleusercontent.com/geougc-cs/AB...                     49.0   \n",
      "1                                                NaN                    201.0   \n",
      "2  https://lh3.googleusercontent.com/geougc-cs/AB...                   2181.0   \n",
      "3  https://lh3.googleusercontent.com/geougc-cs/AB...                     53.0   \n",
      "4  https://lh3.googleusercontent.com/geougc-cs/AB...                    127.0   \n",
      "\n",
      "   temporarilyClosed  qualityLevel  ...  reviewWordCount  sentimentScore  \\\n",
      "0                0.0             2  ...               32        0.001126   \n",
      "1                0.0             1  ...               11        0.999089   \n",
      "2                0.0             1  ...               12        0.999921   \n",
      "3                0.0             2  ...               28        0.999850   \n",
      "4                0.0             0  ...               10        0.997996   \n",
      "\n",
      "   sentimentRatingDiff  readabilityScore  grammarSpellingScore  hasLink  \\\n",
      "0             0.498874          0.771025              1.000000        0   \n",
      "1             0.000911          0.705070              0.909091        0   \n",
      "2             0.499921          0.818550              0.916667        0   \n",
      "3             0.000150          0.355107              0.892857        0   \n",
      "4             0.002004          1.000000              1.000000        0   \n",
      "\n",
      "   categoryrelevanceScore  imageRelevanceScore  imageQualityScore  \\\n",
      "0                0.281248             0.546696           0.856412   \n",
      "1                0.389142                  NaN                NaN   \n",
      "2                0.432605             0.546786           0.997150   \n",
      "3                0.248290             0.532493           0.963426   \n",
      "4                0.279137             0.524121           0.987667   \n",
      "\n",
      "   isAdvertisement  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Google Sheet file ID\n",
    "file_id = \"1xkgCgwFvHSIST_pRXB4zmKRGAqw3Yyti\"\n",
    "\n",
    "# Export as Excel (.xlsx)\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{file_id}/export?format=xlsx\"\n",
    "\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "# Preview\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "150ed82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rule_based(df):\n",
    "    # Ensure publishedAtDate is datetime\n",
    "    df[\"publishedAtDate\"] = pd.to_datetime(df[\"publishedAtDate\"], errors=\"coerce\")\n",
    "    \n",
    "    # Start with all NaN (means \"not yet decided\")\n",
    "    df[\"ruleQualityLabel\"] = np.nan\n",
    "    \n",
    "    # Rule 1: Link → qualityLevel = 0\n",
    "    df.loc[(df[\"hasLink\"] == 1) | (df[\"isAdvertisement\"] == 1), \"ruleQualityLabel\"] = 0\n",
    "\n",
    "    \n",
    "    # Rule 2: Spamming by same user at same location in short time\n",
    "    df = df.sort_values(by=[\"reviewerName\", \"locationName\", \"publishedAtDate\"])\n",
    "    df[\"timeDiff\"] = df.groupby([\"reviewerName\", \"locationName\"])[\"publishedAtDate\"].diff().dt.total_seconds()\n",
    "    \n",
    "    # Suspicious if multiple reviews within 10 minutes (600 sec)\n",
    "    spam_mask = df[\"timeDiff\"].notna() & (df[\"timeDiff\"] < 600)\n",
    "    df.loc[spam_mask, \"ruleQualityLabel\"] = 0\n",
    "    \n",
    "    # Rule 3: Duplicate content (exact match across reviews)\n",
    "    # Flag duplicates but do NOT delete them\n",
    "    duplicate_mask = df.duplicated(subset=[\"reviewText\"], keep=False)\n",
    "    df.loc[duplicate_mask, \"ruleQualityLabel\"] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43b804fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df[\"qualityLevel\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30140c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule Based:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       133\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       0.50      0.50      0.50       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test = apply_rule_based(X_test)\n",
    "rule_labels = X_test[\"ruleQualityLabel\"]\n",
    "X_test = X_test[X_test[\"ruleQualityLabel\"] == 0]\n",
    "print(\"Rule Based:\")\n",
    "print(classification_report(y_true=X_test[\"qualityLevel\"], y_pred=X_test[\"ruleQualityLabel\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b60a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_quality_labels(rule_labels, rf_probs, dual_probs):\n",
    "    \"\"\"\n",
    "    rule_labels: array of 0/1/2 from rule-based model\n",
    "    rf_probs: n_samples x 3 array from RF predict_proba\n",
    "    dual_probs: n_samples x 3 array from dual-head model predict_proba\n",
    "    \"\"\"\n",
    "    n_samples = len(rule_labels)\n",
    "    final = np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    # average the probabilities for samples where rule-based != 0\n",
    "    avg_probs = (rf_probs + dual_probs) / 2\n",
    "\n",
    "    # assign final labels\n",
    "    for i in range(n_samples):\n",
    "        if rule_labels[i] == 0:\n",
    "            final[i] = 0\n",
    "        else:\n",
    "            final[i] = np.argmax(avg_probs[i])\n",
    "    \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a517f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rf\n",
    "with open('random_forest_model.pkl', 'rb') as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb08b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "X = df[[\"readabilityScore\", \"grammarSpellingScore\", \"sentimentRatingDiff\", \"reviewWordCount\", \"imageQualityScore\"]]  \n",
    "y = df[\"qualityLevel\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "rf_probs = rf.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7cf3cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_labels\u001b[49m(rule_labels, rf_probs, dual_probs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_labels' is not defined"
     ]
    }
   ],
   "source": [
    "quality_labels = final_quality_labels(rule_labels, rf_probs, dual_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
